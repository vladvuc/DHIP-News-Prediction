{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c27f59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.metrics import agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5babfa57",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6870e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix(object):\n",
    "\n",
    "\n",
    "    def __init__(self, reference, test, sort_by_count=False):\n",
    "        \"\"\"\n",
    "        Construct a new confusion matrix from a list of reference\n",
    "        values and a corresponding list of test values.\n",
    "\n",
    "        :type reference: list\n",
    "        :param reference: An ordered list of reference values.\n",
    "        :type test: list\n",
    "        :param test: A list of values to compare against the\n",
    "            corresponding reference values.\n",
    "        :raise ValueError: If ``reference`` and ``length`` do not have\n",
    "            the same length.\n",
    "        \"\"\"\n",
    "        if len(reference) != len(test):\n",
    "            raise ValueError(\"Lists must have the same length.\")\n",
    "\n",
    "        # Get a list of all values.\n",
    "        if sort_by_count:\n",
    "            ref_fdist = FreqDist(reference)\n",
    "            test_fdist = FreqDist(test)\n",
    "\n",
    "            def key(v):\n",
    "                return -(ref_fdist[v] + test_fdist[v])\n",
    "\n",
    "            values = sorted(set(reference + test), key=key)\n",
    "        else:\n",
    "            values = sorted(set(reference + test))\n",
    "\n",
    "        # Construct a value->index dictionary\n",
    "        indices = dict((val, i) for (i, val) in enumerate(values))\n",
    "\n",
    "        # Make a confusion matrix table.\n",
    "        confusion = [[0 for val in values] for val in values]\n",
    "        max_conf = 0  # Maximum confusion\n",
    "        for w, g in zip(reference, test):\n",
    "            confusion[indices[w]][indices[g]] += 1\n",
    "            max_conf = max(max_conf, confusion[indices[w]][indices[g]])\n",
    "\n",
    "        #: A list of all values in ``reference`` or ``test``.\n",
    "        self._values = values\n",
    "        #: A dictionary mapping values in ``self._values`` to their indices.\n",
    "        self._indices = indices\n",
    "        #: The confusion matrix itself (as a list of lists of counts).\n",
    "        self._confusion = confusion\n",
    "        #: The greatest count in ``self._confusion`` (used for printing).\n",
    "        self._max_conf = max_conf\n",
    "        #: The total number of values in the confusion matrix.\n",
    "        self._total = len(reference)\n",
    "        #: The number of correct (on-diagonal) values in the matrix.\n",
    "        self._correct = sum(confusion[i][i] for i in range(len(values)))\n",
    "\n",
    "    def __getitem__(self, li_lj_tuple):\n",
    "        \"\"\"\n",
    "        :return: The number of times that value ``li`` was expected and\n",
    "        value ``lj`` was given.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        (li, lj) = li_lj_tuple\n",
    "        i = self._indices[li]\n",
    "        j = self._indices[lj]\n",
    "        return self._confusion[i][j]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<ConfusionMatrix: %s/%s correct>\" % (self._correct, self._total)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.pretty_format()\n",
    "\n",
    "    def pretty_format(\n",
    "        self,\n",
    "        show_percents=False,\n",
    "        values_in_chart=True,\n",
    "        truncate=None,\n",
    "        sort_by_count=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :return: A multi-line string representation of this confusion matrix.\n",
    "        :type truncate: int\n",
    "        :param truncate: If specified, then only show the specified\n",
    "            number of values.  Any sorting (e.g., sort_by_count)\n",
    "            will be performed before truncation.\n",
    "        :param sort_by_count: If true, then sort by the count of each\n",
    "            label in the reference data.  I.e., labels that occur more\n",
    "            frequently in the reference label will be towards the left\n",
    "            edge of the matrix, and labels that occur less frequently\n",
    "            will be towards the right edge.\n",
    "\n",
    "        @todo: add marginals?\n",
    "        \"\"\"\n",
    "        confusion = self._confusion\n",
    "\n",
    "        values = self._values\n",
    "        if sort_by_count:\n",
    "            values = sorted(\n",
    "                values, key=lambda v: -sum(self._confusion[self._indices[v]])\n",
    "            )\n",
    "\n",
    "        if truncate:\n",
    "            values = values[:truncate]\n",
    "\n",
    "        if values_in_chart:\n",
    "            value_strings = [\"%s\" % val for val in values]\n",
    "        else:\n",
    "            value_strings = [str(n + 1) for n in range(len(values))]\n",
    "\n",
    "        # Construct a format string for row values\n",
    "        valuelen = max(len(val) for val in value_strings)\n",
    "        value_format = \"%\" + repr(valuelen) + \"s | \"\n",
    "        # Construct a format string for matrix entries\n",
    "        if show_percents:\n",
    "            entrylen = 6\n",
    "            entry_format = \"%5.1f%%\"\n",
    "            zerostr = \"     .\"\n",
    "        else:\n",
    "            entrylen = len(repr(self._max_conf))\n",
    "            entry_format = \"%\" + repr(entrylen) + \"d\"\n",
    "            zerostr = \" \" * (entrylen - 1) + \".\"\n",
    "\n",
    "        # Write the column values.\n",
    "        s = \"\"\n",
    "        for i in range(valuelen):\n",
    "            s += (\" \" * valuelen) + \" |\"\n",
    "            for val in value_strings:\n",
    "                if i >= valuelen - len(val):\n",
    "                    s += val[i - valuelen + len(val)].rjust(entrylen + 1)\n",
    "                else:\n",
    "                    s += \" \" * (entrylen + 1)\n",
    "            s += \" |\\n\"\n",
    "\n",
    "        # Write a dividing line\n",
    "        s += \"%s-+-%s+\\n\" % (\"-\" * valuelen, \"-\" * ((entrylen + 1) * len(values)))\n",
    "\n",
    "        # Write the entries.\n",
    "        for val, li in zip(value_strings, values):\n",
    "            i = self._indices[li]\n",
    "            s += value_format % val\n",
    "            for lj in values:\n",
    "                j = self._indices[lj]\n",
    "                if confusion[i][j] == 0:\n",
    "                    s += zerostr\n",
    "                elif show_percents:\n",
    "                    s += entry_format % (100.0 * confusion[i][j] / self._total)\n",
    "                else:\n",
    "                    s += entry_format % confusion[i][j]\n",
    "                if i == j:\n",
    "                    prevspace = s.rfind(\" \")\n",
    "                    s = s[:prevspace] + \"<\" + s[prevspace + 1 :] + \">\"\n",
    "                else:\n",
    "                    s += \" \"\n",
    "            s += \"|\\n\"\n",
    "\n",
    "        # Write a dividing line\n",
    "        s += \"%s-+-%s+\\n\" % (\"-\" * valuelen, \"-\" * ((entrylen + 1) * len(values)))\n",
    "\n",
    "        # Write a key\n",
    "        s += \"(row = \" + name_1 + \"; col = \" + name_2 + \")\" + \"\\n\"\n",
    "        if not values_in_chart:\n",
    "            s += \"Value key:\\n\"\n",
    "            for i, value in enumerate(values):\n",
    "                s += \"%6d: %s\\n\" % (i + 1, value)\n",
    "\n",
    "        return s\n",
    "\n",
    "\n",
    "    def key(self):\n",
    "        values = self._values\n",
    "        str = \"Value key:\\n\"\n",
    "        indexlen = len(repr(len(values) - 1))\n",
    "        key_format = \"  %\" + repr(indexlen) + \"d: %s\\n\"\n",
    "        for i in range(len(values)):\n",
    "            str += key_format % (i, values[i])\n",
    "\n",
    "        return str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a23f17",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66252c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/inter-annotator/annotator_agreement_all_final.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "325ff1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>vlad_entity</th>\n",
       "      <th>vlad</th>\n",
       "      <th>shanet_entity</th>\n",
       "      <th>shanet</th>\n",
       "      <th>dhruv_entity</th>\n",
       "      <th>dhruv</th>\n",
       "      <th>spacy_entity</th>\n",
       "      <th>spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Land Was Made For You And Me' — Or Was It?</td>\n",
       "      <td>land</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Land</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Land</td>\n",
       "      <td>LOC</td>\n",
       "      <td>This Land Was Made</td>\n",
       "      <td>WORK_OF_ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Perspective On George Zimmerman That Every P...</td>\n",
       "      <td>George Zimmerman</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>George Zimmerman</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>George Zimmerman</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>George Zimmerman</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Strategy To Combat Crime That McGruff Wished...</td>\n",
       "      <td>McGruff</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>McGruff</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>McGruff</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>McGruff</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could You Go 100 Days Without Food? These Men ...</td>\n",
       "      <td>100 Days</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Men</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>100 Days</td>\n",
       "      <td>DATE</td>\n",
       "      <td>100 Days</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here’s A Map of American Exceptionalism That’s...</td>\n",
       "      <td>American Exceptionalism</td>\n",
       "      <td>NORP</td>\n",
       "      <td>American</td>\n",
       "      <td>NORP</td>\n",
       "      <td>American</td>\n",
       "      <td>NORP</td>\n",
       "      <td>American</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines              vlad_entity  \\\n",
       "0    This Land Was Made For You And Me' — Or Was It?                     land   \n",
       "1  A Perspective On George Zimmerman That Every P...         George Zimmerman   \n",
       "2  A Strategy To Combat Crime That McGruff Wished...                  McGruff   \n",
       "3  Could You Go 100 Days Without Food? These Men ...                 100 Days   \n",
       "4  Here’s A Map of American Exceptionalism That’s...  American Exceptionalism   \n",
       "\n",
       "     vlad     shanet_entity  shanet      dhruv_entity   dhruv  \\\n",
       "0     LOC              Land     LOC              Land     LOC   \n",
       "1  PERSON  George Zimmerman  PERSON  George Zimmerman  PERSON   \n",
       "2  PERSON           McGruff  PERSON           McGruff  PERSON   \n",
       "3    DATE               Men  PERSON          100 Days    DATE   \n",
       "4    NORP          American    NORP          American    NORP   \n",
       "\n",
       "         spacy_entity        spacy  \n",
       "0  This Land Was Made  WORK_OF_ART  \n",
       "1    George Zimmerman       PERSON  \n",
       "2             McGruff       PERSON  \n",
       "3            100 Days         DATE  \n",
       "4            American         NORP  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6dbd0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 51 lines.\n",
      "Shanet 51\n",
      "Spacy 51\n",
      "Confusion matrix:\n",
      "            | W                     |\n",
      "            | O                     |\n",
      "            | R                     |\n",
      "            | K                     |\n",
      "            | _               U     |\n",
      "            | O   P           N     |\n",
      "            | F   E         M K   E |\n",
      "            | _ D R T N     O N   V |\n",
      "            | A A S I O G O N O L E |\n",
      "            | R T O M R P R E W O N |\n",
      "            | T E N E P E G Y N C T |\n",
      "------------+-----------------------+\n",
      "WORK_OF_ART |<8>. 1 . . . 1 . . . . |\n",
      "       DATE | 2<5>. . . . . . . . 1 |\n",
      "     PERSON | . 1<6>. . . . . . . . |\n",
      "       TIME | . . .<6>. . . . . . . |\n",
      "       NORP | . . . .<3>. 2 . . . . |\n",
      "        GPE | . . 1 . .<3>. . . . . |\n",
      "        ORG | 1 . . . . 1<2>. . . . |\n",
      "      MONEY | . . . . . . .<3>. . . |\n",
      "    UNKNOWN | 1 1 . . . . . .<.>. 1 |\n",
      "        LOC | 1 . . . . . . . .<.>. |\n",
      "      EVENT | . . . . . . . . . .<.>|\n",
      "------------+-----------------------+\n",
      "(row = Shanet; col = Spacy)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# name_1 = \"Vlad\"\n",
    "name_1 = \"Shanet\"\n",
    "# name_1 = \"Dhruv\"\n",
    "# name_2 = \"Shanet\"\n",
    "# name_2 = \"Dhruv\"\n",
    "name_2 = \"Spacy\"\n",
    "\n",
    "def demo():\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "\n",
    "    with open('../data/inter-annotator/annotator_agreement_all_final.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "        line_count = 0\n",
    "\n",
    "        for row in csv_reader:\n",
    "            # VLAD\n",
    "            #list1.append(row[2])\n",
    "            # SHANET\n",
    "            #list1.append(row[4])\n",
    "            # DHRUV\n",
    "            list1.append(row[6])\n",
    "            # SPACY\n",
    "            list2.append(row[8])\n",
    "            line_count += 1\n",
    "        print(f'Processed {line_count-1} lines.')\n",
    "    a1=list1[1:]\n",
    "    a2=list2[1:]\n",
    "\n",
    "    print(name_1, len(list1[1:]))\n",
    "    print(name_2, len(list2[1:]))\n",
    "    print(\"Confusion matrix:\")\n",
    "\n",
    "    print(ConfusionMatrix(a1, a2).pretty_format(sort_by_count=True))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2964f5",
   "metadata": {},
   "source": [
    "## Kappa score for annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583278c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>vlad_entity</th>\n",
       "      <th>vlad</th>\n",
       "      <th>shanet_entity</th>\n",
       "      <th>shanet</th>\n",
       "      <th>dhruv_entity</th>\n",
       "      <th>dhruv</th>\n",
       "      <th>spacy_entity</th>\n",
       "      <th>spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Land Was Made For You And Me' — Or Was It?</td>\n",
       "      <td>land</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Land</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Land</td>\n",
       "      <td>LOC</td>\n",
       "      <td>This Land Was Made</td>\n",
       "      <td>WORK_OF_ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Perspective On George Zimmerman That Every P...</td>\n",
       "      <td>George Zimmerman</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>George Zimmerman</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>George Zimmerman</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>George Zimmerman</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Strategy To Combat Crime That McGruff Wished...</td>\n",
       "      <td>McGruff</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>McGruff</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>McGruff</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>McGruff</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could You Go 100 Days Without Food? These Men ...</td>\n",
       "      <td>100 Days</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Men</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>100 Days</td>\n",
       "      <td>DATE</td>\n",
       "      <td>100 Days</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here’s A Map of American Exceptionalism That’s...</td>\n",
       "      <td>American Exceptionalism</td>\n",
       "      <td>NORP</td>\n",
       "      <td>American</td>\n",
       "      <td>NORP</td>\n",
       "      <td>American</td>\n",
       "      <td>NORP</td>\n",
       "      <td>American</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines              vlad_entity  \\\n",
       "0    This Land Was Made For You And Me' — Or Was It?                     land   \n",
       "1  A Perspective On George Zimmerman That Every P...         George Zimmerman   \n",
       "2  A Strategy To Combat Crime That McGruff Wished...                  McGruff   \n",
       "3  Could You Go 100 Days Without Food? These Men ...                 100 Days   \n",
       "4  Here’s A Map of American Exceptionalism That’s...  American Exceptionalism   \n",
       "\n",
       "     vlad     shanet_entity  shanet      dhruv_entity   dhruv  \\\n",
       "0     LOC              Land     LOC              Land     LOC   \n",
       "1  PERSON  George Zimmerman  PERSON  George Zimmerman  PERSON   \n",
       "2  PERSON           McGruff  PERSON           McGruff  PERSON   \n",
       "3    DATE               Men  PERSON          100 Days    DATE   \n",
       "4    NORP          American    NORP          American    NORP   \n",
       "\n",
       "         spacy_entity        spacy  \n",
       "0  This Land Was Made  WORK_OF_ART  \n",
       "1    George Zimmerman       PERSON  \n",
       "2             McGruff       PERSON  \n",
       "3            100 Days         DATE  \n",
       "4            American         NORP  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf78e1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files/annotator_agreement_all_final.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'files/annotator_agreement_all_final.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m inputfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles/annotator_agreement_all_final.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputfile)\n\u001b[0;32m----> 3\u001b[0m merged_df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvlad_entity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvlad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshanet_entity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshanet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdhruv_entity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdhruv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy_entity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_df\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'files/annotator_agreement_all_final.csv'"
     ]
    }
   ],
   "source": [
    "inputfile='..//annotator_agreement_all_final.csv'\n",
    "print(inputfile)\n",
    "merged_df=pd.read_csv(inputfile, delimiter=';', header = 0, index_col=0)\n",
    "merged_df.columns=[\"vlad_entity\", \"vlad\", \"shanet_entity\", \"shanet\", \"dhruv_entity\", \"dhruv\", \"spacy_entity\", \"spacy\"]\n",
    "\n",
    "print(merged_df.shape)\n",
    "\n",
    "labels_matched_df = merged_df.dropna()\n",
    "\n",
    "# Reformat the data into the form AnnotationTask\n",
    "#  expects.\n",
    "data = []\n",
    "for idx, row in labels_matched_df.iterrows():\n",
    "    data.append((\"a1\", idx, row[\"shanet\"]))\n",
    "    data.append((\"a2\", idx, row[\"vlad\"]))\n",
    "\n",
    "atask = agreement.AnnotationTask(data=data)\n",
    "\n",
    "print(\"Percentage agreement:\", atask.avg_Ao())\n",
    "print(\"Cohen's Kappa:\", atask.kappa())\n",
    "#print(\"Fleiss's Kappa:\", atask.multi_kappa())\n",
    "#print(\"Krippendorf's alpha:\", atask.alpha())\n",
    "\n",
    "# This function maps labels into a numeric space,\n",
    "# . so we can rely on the ordering of labels.\n",
    "def priority_distance(left_label, right_label):\n",
    "    mapped_labels = {\n",
    "        \"Critical\": 4,\n",
    "        \"High\": 3,\n",
    "        \"Medium\": 2,\n",
    "        \"Low\": 1,\n",
    "    }\n",
    "    left_i = mapped_labels[left_label]\n",
    "    right_i = mapped_labels[right_label]\n",
    "\n",
    "    return abs(left_i - right_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eced41",
   "metadata": {},
   "source": [
    "# Extracting disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34bddab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0187c9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
